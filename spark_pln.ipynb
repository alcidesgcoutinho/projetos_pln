{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[],"authorship_tag":"ABX9TyNguyKHU4gMW/Ewd4jPR731"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"markdown","source":["# Instalar Spark, importar funções, criar seção e importar dados"],"metadata":{"id":"YdhTaFBkfu7q"}},{"cell_type":"code","execution_count":1,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"Uy1_BWEsceNZ","executionInfo":{"status":"ok","timestamp":1742673812814,"user_tz":180,"elapsed":9584,"user":{"displayName":"Alcide Gabriel P. Coutinho Maciel","userId":"18324768684938800470"}},"outputId":"9845658b-600d-4f23-8d32-b95cc2825d0e"},"outputs":[{"output_type":"stream","name":"stdout","text":["Requirement already satisfied: pyspark in /usr/local/lib/python3.11/dist-packages (3.5.5)\n","Requirement already satisfied: py4j in /usr/local/lib/python3.11/dist-packages (0.10.9.7)\n"]}],"source":["!pip install pyspark py4j"]},{"cell_type":"code","source":["from pyspark.sql import SparkSession\n","from pyspark.sql import functions as f\n"],"metadata":{"id":"eR3L1LfldCv0","executionInfo":{"status":"ok","timestamp":1742674424549,"user_tz":180,"elapsed":2,"user":{"displayName":"Alcide Gabriel P. Coutinho Maciel","userId":"18324768684938800470"}}},"execution_count":8,"outputs":[]},{"cell_type":"code","source":["spark = SparkSession.builder.appName(\"teste_inicial\").getOrCreate()"],"metadata":{"id":"2cSCkWjmdC3T","executionInfo":{"status":"ok","timestamp":1742674192581,"user_tz":180,"elapsed":9849,"user":{"displayName":"Alcide Gabriel P. Coutinho Maciel","userId":"18324768684938800470"}}},"execution_count":3,"outputs":[]},{"cell_type":"markdown","source":["- header => True define que a primeira linha tem o nome das colunas.\n","- inferSchema => True faz o spark detectar os dados"],"metadata":{"id":"qaXrVPLQe1-v"}},{"cell_type":"code","source":["df = spark.read.csv(\"/content/sample_data/california_housing_test.csv\", header=True, inferSchema=True)"],"metadata":{"id":"Seid7itjehT8","executionInfo":{"status":"ok","timestamp":1742674284689,"user_tz":180,"elapsed":10617,"user":{"displayName":"Alcide Gabriel P. Coutinho Maciel","userId":"18324768684938800470"}}},"execution_count":5,"outputs":[]},{"cell_type":"markdown","source":["# Importar biblioteca Spark NLP"],"metadata":{"id":"2HFxDE3Rf6Bd"}},{"cell_type":"code","source":["!pip install pyspark==3.5.0 spark-nlp"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"_akTw7MBehs8","executionInfo":{"status":"ok","timestamp":1742674670875,"user_tz":180,"elapsed":5533,"user":{"displayName":"Alcide Gabriel P. Coutinho Maciel","userId":"18324768684938800470"}},"outputId":"f830b53a-5d11-4882-b57b-89055a7e8a81"},"execution_count":1,"outputs":[{"output_type":"stream","name":"stdout","text":["Requirement already satisfied: pyspark==3.5.0 in /usr/local/lib/python3.11/dist-packages (3.5.0)\n","Requirement already satisfied: spark-nlp in /usr/local/lib/python3.11/dist-packages (5.5.3)\n","Requirement already satisfied: py4j==0.10.9.7 in /usr/local/lib/python3.11/dist-packages (from pyspark==3.5.0) (0.10.9.7)\n"]}]},{"cell_type":"code","source":["import sparknlp\n","from sparknlp.base import *\n","from sparknlp.annotator import *\n","from sparknlp.training import CoNLL"],"metadata":{"id":"8kqMPekMeh2c","executionInfo":{"status":"ok","timestamp":1742674731839,"user_tz":180,"elapsed":2,"user":{"displayName":"Alcide Gabriel P. Coutinho Maciel","userId":"18324768684938800470"}}},"execution_count":4,"outputs":[]},{"cell_type":"code","source":["spark = sparknlp.start()"],"metadata":{"id":"Cvw0l0dOgBcV","executionInfo":{"status":"ok","timestamp":1742674731834,"user_tz":180,"elapsed":56543,"user":{"displayName":"Alcide Gabriel P. Coutinho Maciel","userId":"18324768684938800470"}}},"execution_count":3,"outputs":[]},{"cell_type":"code","source":[],"metadata":{"id":"AZQJmZ-LguxR"},"execution_count":null,"outputs":[]}]}